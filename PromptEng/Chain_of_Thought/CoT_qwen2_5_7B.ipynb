{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQvwjC7FQ2pe",
        "outputId": "e6e2dbdc-6f4c-4464-eb63-b55bc673f4a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: rouge in /usr/local/lib/python3.11/dist-packages (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from rouge) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install -q datasets\n",
        "!pip install rouge"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "7428dc1ff5d74934a24cac63ef0bd2a2",
            "a4d8fbbc8a2048f88a7b742068385573",
            "f4d52c26fd9b467d9bcf1e5dd3fa2545",
            "d8ccf3b615ae44debba2ab6e18ec1dd6",
            "aeed629be7d14c0e92c7a6609b0c6d06",
            "3573a6b3ee684e6989bb4b6f729b0b91",
            "adc83d6f5b6c49a386ab86cb79456cb6",
            "722694acc58f4a798d13a4ccafce8379",
            "7b9f7822a08041b3a86439467b2761c1",
            "76aec4554c4e47f1be9979cd36c87886",
            "d23a906a054e48b380f6873bb3aa78b7"
          ]
        },
        "id": "IhmMVy3OQxAp",
        "outputId": "e3fae740-47d4-4c7b-db70-4dca20301a28"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7428dc1ff5d74934a24cac63ef0bd2a2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Example Operations Used in Prompt:\n",
            "==================================================\n",
            "\n",
            "Operation Type: arithmetic\n",
            "Operations: add(75.0, 72.7), divide(#0, 20)\n",
            "\n",
            "Operation Type: arithmetic\n",
            "Operations: subtract(959.2, 991.1), divide(#0, 991.1)\n",
            "\n",
            "Operation Type: boolean\n",
            "Operations: multiply(607, 18.13), multiply(#0, const_1000), multiply(3.3, const_1000000), greater(#1, #2)\n",
            "\n",
            "Operation Type: table\n",
            "Operations: table_sum(cash flows on retained interests, none)\n",
            "\n",
            "Operation Type: table\n",
            "Operations: table_max(cumulative foreign currency translation, none)\n",
            "\n",
            "Operation Type: table\n",
            "Operations: table_min(expected volatility, none), table_max(expected volatility, none), subtract(#1, #0)\n",
            "\n",
            "Operation Type: table\n",
            "Operations: table_average(2016, none)\n",
            "\n",
            "Operation Type: exponential\n",
            "Operations: add(const_1, 2.0%), exp(#0, 7), multiply(397, #1)\n",
            "\n",
            "Testing with chain of thought reasoning:\n",
            "==================================================\n",
            "\n",
            "Test Sample 1\n",
            "------------------------------\n",
            "Operation Type: arithmetic\n",
            "Question: what was the purchase price of common stock acquired under the espp in 2018?\n",
            "Expected Operations: multiply(90%, 73.62)\n",
            "Expected Answer: 66.26\n",
            "\n",
            "Model Response:\n",
            "Operations needed: multiply(table_average(fair market value, 'end'), 0.85)\n",
            "Answer: The exact mathematical expression using function notation for the purchase price of common stock acquired under the ESPP in 2018 is:\n",
            "\n",
            "ROUGE Scores:\n",
            "ROUGE-1 F1: 0.000\n",
            "ROUGE-2 F1: 0.000\n",
            "ROUGE-L F1: 0.000\n",
            "\n",
            "Test Sample 2\n",
            "------------------------------\n",
            "Operation Type: arithmetic\n",
            "Question: in 2014 what was the decrease in printing papers net sales in millions\n",
            "Expected Operations: subtract(5.7, 6.2)\n",
            "Expected Answer: 500\n",
            "\n",
            "Model Response:\n",
            "Operations needed: subtract(2013, 2014)\n",
            "Answer: 485 (This is the difference in net sales between 2013 and 2014)\n",
            "\n",
            "ROUGE Scores:\n",
            "ROUGE-1 F1: 0.000\n",
            "ROUGE-2 F1: 0.000\n",
            "ROUGE-L F1: 0.000\n",
            "\n",
            "Test Sample 3\n",
            "------------------------------\n",
            "Operation Type: arithmetic\n",
            "Question: what is the annual expense for entergy texas incurred from the series mortgage bonds due february 2019 , in millions?\n",
            "Expected Operations: multiply(500, 7.125%)\n",
            "Expected Answer: 35.6\n",
            "\n",
            "Model Response:\n",
            "Operations needed: divide(multiply(500, 7.125%), 365)\n",
            "Answer: 1.2083333333333333 ---\n",
            "\n",
            "ROUGE Scores:\n",
            "ROUGE-1 F1: 0.286\n",
            "ROUGE-2 F1: 0.000\n",
            "ROUGE-L F1: 0.286\n",
            "\n",
            "Test Sample 4\n",
            "------------------------------\n",
            "Operation Type: table\n",
            "Question: in millions for 2017 , 2016 , and 2015 , what was the minimum amount of equity securities?\n",
            "Expected Operations: table_min(equity securities, none)\n",
            "Expected Answer: 2573\n",
            "\n",
            "Model Response:\n",
            "Operations needed: table_min(equity securities, none)\n",
            "Answer: 2573\n",
            "\n",
            "ROUGE Scores:\n",
            "ROUGE-1 F1: 1.000\n",
            "ROUGE-2 F1: 1.000\n",
            "ROUGE-L F1: 1.000\n",
            "\n",
            "Test Sample 5\n",
            "------------------------------\n",
            "Operation Type: arithmetic\n",
            "Question: what was the total purchase price in cash payment for the sentinelle medical acquisition?\n",
            "Expected Operations: multiply(250.0, const_3), add(84.8, #0)\n",
            "Expected Answer: $ 834.8 million\n",
            "\n",
            "Model Response:\n",
            "Operations needed: table_sum(cash, none)\n",
            "Answer: 84751\n",
            "\n",
            "ROUGE Scores:\n",
            "ROUGE-1 F1: 0.000\n",
            "ROUGE-2 F1: 0.000\n",
            "ROUGE-L F1: 0.000\n",
            "\n",
            "Test Sample 6\n",
            "------------------------------\n",
            "Operation Type: arithmetic\n",
            "Question: what is the combined number of equity compensation plans approved by security holders\n",
            "Expected Operations: add(2956907, 2786760)\n",
            "Expected Answer: 5743667\n",
            "\n",
            "Model Response:\n",
            "Operations needed: add(2956907, 2786760)\n",
            "Answer: 5743667\n",
            "\n",
            "ROUGE Scores:\n",
            "ROUGE-1 F1: 1.000\n",
            "ROUGE-2 F1: 1.000\n",
            "ROUGE-L F1: 1.000\n",
            "\n",
            "Test Sample 7\n",
            "------------------------------\n",
            "Operation Type: arithmetic\n",
            "Question: what was the percentage change in total operating expenses between 2016 and 2018?\n",
            "Expected Operations: subtract(2272, 5042), divide(#0, 5042)\n",
            "Expected Answer: -55%\n",
            "\n",
            "Model Response:\n",
            "Operations needed: divide(subtract(2272, 5042), 5042) * 100\n",
            "Answer: -54.8% (if the values provided accurately represent the necessary figures) ---\n",
            "\n",
            "ROUGE Scores:\n",
            "ROUGE-1 F1: 0.444\n",
            "ROUGE-2 F1: 0.000\n",
            "ROUGE-L F1: 0.444\n",
            "\n",
            "Test Sample 8\n",
            "------------------------------\n",
            "Operation Type: arithmetic\n",
            "Question: what is the growth rate in operating profit for mst in 2011?\n",
            "Expected Operations: subtract(645, 713), divide(#0, 713)\n",
            "Expected Answer: -9.5%\n",
            "\n",
            "Model Response:\n",
            "Operations needed: **\n",
            "Answer: ** -9.57%\n",
            "\n",
            "ROUGE Scores:\n",
            "ROUGE-1 F1: 0.000\n",
            "ROUGE-2 F1: 0.000\n",
            "ROUGE-L F1: 0.000\n",
            "\n",
            "Test Sample 9\n",
            "------------------------------\n",
            "Operation Type: arithmetic\n",
            "Question: what is the 2020 net derivative balance in billions?\n",
            "Expected Operations: subtract(84676, 65714)\n",
            "Expected Answer: 18962\n",
            "\n",
            "Model Response:\n",
            "Operations needed: add(trading assets 2013 derivative receivables, trading liabilities 2013 derivative payables), subtract(#0, #1)\n",
            "Answer: -0.021\n",
            "\n",
            "ROUGE Scores:\n",
            "ROUGE-1 F1: 0.000\n",
            "ROUGE-2 F1: 0.000\n",
            "ROUGE-L F1: 0.000\n",
            "\n",
            "Test Sample 10\n",
            "------------------------------\n",
            "Operation Type: arithmetic\n",
            "Question: what is the total revenue for the fiscal year of 2015?\n",
            "Expected Operations: add(1570, 1745), add(#0, 1800), add(#1, 1905)\n",
            "Expected Answer: 7020\n",
            "\n",
            "Model Response:\n",
            "Operations needed: add(1570, add(1745, add(1800, 1905)))\n",
            "Answer: 6020\n",
            "\n",
            "ROUGE Scores:\n",
            "ROUGE-1 F1: 0.200\n",
            "ROUGE-2 F1: 0.000\n",
            "ROUGE-L F1: 0.200\n",
            "\n",
            "Overall ROUGE Scores:\n",
            "==================================================\n",
            "Average ROUGE-1 F1: 0.293\n",
            "Average ROUGE-2 F1: 0.200\n",
            "Average ROUGE-L F1: 0.293\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "from datasets import load_dataset\n",
        "import json\n",
        "from typing import List, Dict, Any\n",
        "import random\n",
        "from collections import Counter\n",
        "\n",
        "class PromptTester:\n",
        "    def __init__(self, model_name: str, hf_token: str):\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(model_name, token=hf_token)\n",
        "        self.model = AutoModelForCausalLM.from_pretrained(\n",
        "            model_name,\n",
        "            token=hf_token,\n",
        "            device_map=\"auto\",\n",
        "            torch_dtype=torch.bfloat16\n",
        "        )\n",
        "        self.dataset = load_dataset(\"n3Er/FinQA-Infix\")\n",
        "        self.examples = self.get_curated_examples()\n",
        "\n",
        "    def categorize_operation(self, operation: str) -> str:\n",
        "        \"\"\"Categorize the type of operation\"\"\"\n",
        "        if any(op in operation for op in [\"table_max\", \"table_min\", \"table_sum\", \"table_average\"]):\n",
        "            return \"table\"\n",
        "        elif any(op in operation for op in [\"greater\", \"less\", \"equal\"]):\n",
        "            return \"boolean\"\n",
        "        elif \"exp\" in operation:\n",
        "            return \"exponential\"\n",
        "        else:\n",
        "            return \"arithmetic\"\n",
        "\n",
        "    def get_curated_examples(self) -> List[Dict]:\n",
        "        \"\"\"Get diverse examples covering all operation types and operators\"\"\"\n",
        "        train_data = list(self.dataset['train'])\n",
        "        # Filter for examples with valid operations and answers\n",
        "        valid_examples = [\n",
        "            ex for ex in train_data\n",
        "            if ex['program_re'] and ex['answer'] is not None\n",
        "        ]\n",
        "        # Define operation subtypes we want to include\n",
        "        operation_subtypes = {\n",
        "            \"arithmetic\": {\n",
        "                \"addition\": \"add(\",\n",
        "                \"subtraction\": \"subtract(\",\n",
        "                \"multiplication\": \"multiply(\",\n",
        "                \"division\": \"divide(\",\n",
        "                \"percentage\": \"multiply( divide(\"\n",
        "            },\n",
        "            \"table\": {\n",
        "                \"sum\": \"table_sum(\",\n",
        "                \"max\": \"table_max(\",\n",
        "                \"min\": \"table_min(\",\n",
        "                \"average\": \"table_average(\"\n",
        "            },\n",
        "            \"boolean\": {\n",
        "                \"greater\": \"greater(\",\n",
        "                \"less\": \"less(\",\n",
        "                \"equal\": \"equal(\"\n",
        "            },\n",
        "            \"exponential\": {\n",
        "                \"power\": \"exp(\"\n",
        "            }\n",
        "        }\n",
        "        # Initialize collection of examples\n",
        "        selected_examples = []\n",
        "        # For each main operation type\n",
        "        for op_type, subtypes in operation_subtypes.items():\n",
        "            for subtype, operator in subtypes.items():\n",
        "                # Find examples containing this operator\n",
        "                matching_examples = [\n",
        "                    ex for ex in valid_examples\n",
        "                    if operator in ex['program_re']\n",
        "                    and not any(operator in selected['program_re'] for selected in selected_examples)\n",
        "                ]\n",
        "                # Select the first matching example\n",
        "                for example in matching_examples:\n",
        "                    if len(selected_examples) < 8:  # Limit to 8 total examples\n",
        "                        selected_examples.append(example)\n",
        "                        break\n",
        "        return selected_examples\n",
        "\n",
        "    def format_table(self, table: List[List[Any]]) -> str:\n",
        "        if not table:\n",
        "            return \"\"\n",
        "        return \"\\n\".join(\" | \".join(str(cell) for cell in row) for row in table)\n",
        "\n",
        "    def format_context(self, example: Dict) -> str:\n",
        "        \"\"\"Format context consistently\"\"\"\n",
        "        parts = []\n",
        "        if example['pre_text']:\n",
        "            parts.append(\"Context before:\")\n",
        "            parts.append(' '.join(example['pre_text']))\n",
        "        if example['table']:\n",
        "            parts.append(\"\\nTable:\")\n",
        "            parts.append(self.format_table(example['table']))\n",
        "        if example['post_text']:\n",
        "            parts.append(\"\\nContext after:\")\n",
        "            parts.append(' '.join(example['post_text']))\n",
        "        return \"\\n\".join(parts)\n",
        "\n",
        "    def create_prompt(self, example: Dict) -> str:\n",
        "        \"\"\"Create prompt with chain of thought reasoning\"\"\"\n",
        "        demonstrations = []\n",
        "        for demo in self.examples:  # Using all examples\n",
        "            demo_text = f\"\"\"Question: {demo['question']}\n",
        "Context:\n",
        "{self.format_context(demo)}\n",
        "Think through the solution:\n",
        "1. Looking at the values in the context:\n",
        "   - What specific numbers are we comparing or calculating with?\n",
        "   - Is this a percentage change, ratio, or absolute difference?\n",
        "2. For percentage changes: use divide(subtract(new_value, old_value), old_value) then multiply by 100\n",
        "   For ratios: use divide(numerator, denominator)\n",
        "   For differences: use subtract(new_value, old_value)\n",
        "3. The exact calculation needed is:\n",
        "Operations: {demo['program_re']}\n",
        "4. This gives us:\n",
        "Result: {demo['answer']}\n",
        "---\"\"\"\n",
        "            demonstrations.append(demo_text)\n",
        "        context = self.format_context(example)\n",
        "        return f\"\"\"Solve each financial question by thinking through the steps carefully.\n",
        "Always write the exact mathematical expression using function notation (add(), subtract(), multiply(), divide(), greater(), less(), table_sum(), table_max(), table_average(), exp(), etc.).\n",
        "Examples:\n",
        "{chr(10).join(demonstrations)}\n",
        "For this question:\n",
        "Question: {example['question']}\n",
        "Context:\n",
        "{context}\n",
        "Think through your solution:\n",
        "1. Identify the exact numbers needed from the context\n",
        "2. For percentage changes: use divide(subtract(new_value, old_value), old_value) then multiply by 100\n",
        "   For ratios: use divide(numerator, denominator)\n",
        "   For differences: use subtract(new_value, old_value)\n",
        "3. Write the complete mathematical expression using function notation\n",
        "You must provide both:\n",
        "Operations: [write the exact mathematical expression using function notation]\n",
        "Result: [result]\"\"\"\n",
        "\n",
        "    def extract_response(self, response: str) -> Dict[str, str]:\n",
        "        \"\"\"Extract operations and result with better handling of variations\"\"\"\n",
        "        operations = None\n",
        "        answer = None\n",
        "        # Clean up the response\n",
        "        lines = [line.strip() for line in response.split('\\n') if line.strip()]\n",
        "        # Handle variations in format\n",
        "        for line in lines:\n",
        "            if \"Operations:\" in line:\n",
        "                operations = line.split(\"Operations:\")[-1].strip()\n",
        "                operations = operations.replace('[write the exact mathematical expression using function notation]', '').strip()\n",
        "                operations = operations.replace('[operations]', '').strip()\n",
        "                if operations == 'None' or operations == '---':\n",
        "                    operations = None\n",
        "            elif \"Result:\" in line:\n",
        "                answer = line.split(\"Result:\")[-1].strip()\n",
        "                answer = answer.replace('[result]', '').strip()\n",
        "                if answer == 'None' or answer == '---' or answer == '(as a number)':\n",
        "                    answer = None\n",
        "        return {\n",
        "            \"operations\": operations,\n",
        "            \"answer\": answer\n",
        "        }\n",
        "\n",
        "    def evaluate_response(self, expected_ops: str, predicted_ops: str) -> Dict[str, float]:\n",
        "        \"\"\"Evaluate the response using ROUGE metrics\"\"\"\n",
        "        try:\n",
        "            from rouge import Rouge\n",
        "        except ImportError:\n",
        "            print(\"Rouge package not found. Installing rouge...\")\n",
        "            import subprocess\n",
        "            import sys\n",
        "            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"rouge\"])\n",
        "            from rouge import Rouge\n",
        "        metrics = {}\n",
        "        # Initialize Rouge for operation comparison\n",
        "        rouge = Rouge()\n",
        "        # Evaluate operations using Rouge if both exist\n",
        "        if expected_ops and predicted_ops:\n",
        "            try:\n",
        "                # Calculate Rouge scores\n",
        "                rouge_scores = rouge.get_scores(predicted_ops, expected_ops)[0]\n",
        "                metrics['rouge1_f'] = rouge_scores['rouge-1']['f']\n",
        "                metrics['rouge2_f'] = rouge_scores['rouge-2']['f']\n",
        "                metrics['rougeL_f'] = rouge_scores['rouge-l']['f']\n",
        "            except Exception:\n",
        "                metrics['rouge1_f'] = 0.0\n",
        "                metrics['rouge2_f'] = 0.0\n",
        "                metrics['rougeL_f'] = 0.0\n",
        "        else:\n",
        "            metrics['rouge1_f'] = 0.0\n",
        "            metrics['rouge2_f'] = 0.0\n",
        "            metrics['rougeL_f'] = 0.0\n",
        "        return metrics\n",
        "\n",
        "    def test_prompts(self, num_samples: int = 10) -> None:\n",
        "        \"\"\"Test with chain of thought prompting and evaluate using ROUGE\"\"\"\n",
        "        test_samples = []\n",
        "        example_ids = {ex['id'] for ex in self.examples}\n",
        "        for sample in random.sample(list(self.dataset['train']), num_samples + len(example_ids)):\n",
        "            if sample['id'] not in example_ids and len(test_samples) < num_samples:\n",
        "                test_samples.append(sample)\n",
        "        print(\"\\nExample Operations Used in Prompt:\")\n",
        "        print(\"=\" * 50)\n",
        "        for ex in self.examples:\n",
        "            print(f\"\\nOperation Type: {self.categorize_operation(ex['program_re'])}\")\n",
        "            print(f\"Operations: {ex['program_re']}\")\n",
        "        print(\"\\nTesting with chain of thought reasoning:\")\n",
        "        print(\"=\" * 50)\n",
        "        # Collect metrics across all samples\n",
        "        all_metrics = []\n",
        "        for idx, sample in enumerate(test_samples, 1):\n",
        "            print(f\"\\nTest Sample {idx}\")\n",
        "            print(\"-\" * 30)\n",
        "            print(f\"Operation Type: {self.categorize_operation(sample['program_re'])}\")\n",
        "            print(f\"Question: {sample['question']}\")\n",
        "            print(f\"Expected Operations: {sample['program_re']}\")\n",
        "            print(f\"Expected Answer: {sample['answer']}\")\n",
        "            # Get response with chain of thought\n",
        "            prompt = self.create_prompt(sample)\n",
        "            inputs = self.tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
        "            with torch.no_grad():\n",
        "                outputs = self.model.generate(\n",
        "                    **inputs,\n",
        "                    max_new_tokens=200,\n",
        "                    temperature=0.7,\n",
        "                    top_p=0.95,\n",
        "                    do_sample=True,\n",
        "                    num_return_sequences=1,\n",
        "                    pad_token_id=self.tokenizer.eos_token_id\n",
        "                )\n",
        "            response = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "            extracted = self.extract_response(response)\n",
        "            print(\"\\nModel Response:\")\n",
        "            print(f\"Operations needed: {extracted['operations']}\")\n",
        "            print(f\"Answer: {extracted['answer']}\")\n",
        "            # Evaluate the response using ROUGE\n",
        "            metrics = self.evaluate_response(\n",
        "                sample['program_re'],\n",
        "                extracted['operations']\n",
        "            )\n",
        "            all_metrics.append(metrics)\n",
        "            print(\"\\nROUGE Scores:\")\n",
        "            print(f\"ROUGE-1 F1: {metrics['rouge1_f']:.3f}\")\n",
        "            print(f\"ROUGE-2 F1: {metrics['rouge2_f']:.3f}\")\n",
        "            print(f\"ROUGE-L F1: {metrics['rougeL_f']:.3f}\")\n",
        "        # Calculate and display average metrics\n",
        "        avg_metrics = {\n",
        "            metric: sum(m[metric] for m in all_metrics) / len(all_metrics)\n",
        "            for metric in all_metrics[0].keys()\n",
        "        }\n",
        "        print(\"\\nOverall ROUGE Scores:\")\n",
        "        print(\"=\" * 50)\n",
        "        print(f\"Average ROUGE-1 F1: {avg_metrics['rouge1_f']:.3f}\")\n",
        "        print(f\"Average ROUGE-2 F1: {avg_metrics['rouge2_f']:.3f}\")\n",
        "        print(f\"Average ROUGE-L F1: {avg_metrics['rougeL_f']:.3f}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    tester = PromptTester(\n",
        "        model_name=\"Qwen/Qwen2.5-7B-Instruct\",\n",
        "        hf_token=\"your_private_token\"\n",
        "    )\n",
        "    tester.test_prompts(num_samples=10)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3573a6b3ee684e6989bb4b6f729b0b91": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "722694acc58f4a798d13a4ccafce8379": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7428dc1ff5d74934a24cac63ef0bd2a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a4d8fbbc8a2048f88a7b742068385573",
              "IPY_MODEL_f4d52c26fd9b467d9bcf1e5dd3fa2545",
              "IPY_MODEL_d8ccf3b615ae44debba2ab6e18ec1dd6"
            ],
            "layout": "IPY_MODEL_aeed629be7d14c0e92c7a6609b0c6d06"
          }
        },
        "76aec4554c4e47f1be9979cd36c87886": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b9f7822a08041b3a86439467b2761c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a4d8fbbc8a2048f88a7b742068385573": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3573a6b3ee684e6989bb4b6f729b0b91",
            "placeholder": "​",
            "style": "IPY_MODEL_adc83d6f5b6c49a386ab86cb79456cb6",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "adc83d6f5b6c49a386ab86cb79456cb6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aeed629be7d14c0e92c7a6609b0c6d06": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d23a906a054e48b380f6873bb3aa78b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d8ccf3b615ae44debba2ab6e18ec1dd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_76aec4554c4e47f1be9979cd36c87886",
            "placeholder": "​",
            "style": "IPY_MODEL_d23a906a054e48b380f6873bb3aa78b7",
            "value": " 4/4 [00:05&lt;00:00,  1.36s/it]"
          }
        },
        "f4d52c26fd9b467d9bcf1e5dd3fa2545": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_722694acc58f4a798d13a4ccafce8379",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7b9f7822a08041b3a86439467b2761c1",
            "value": 4
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
